{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6IjYsgkL_Pi"
      },
      "source": [
        "Download Model Checkpoint\n",
        "\n",
        "Download the **ViT-Huge (vit_h)** model checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HETS78q3L_Pj",
        "outputId": "ad8a73ed-c812-42fb-deee-fcf252d895f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2445M  100 2445M    0     0  48.2M      0  0:00:50  0:00:50 --:--:-- 48.8M0:00:55  0:00:01  0:00:54 43.6M0:02 45.0M\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Download the model checkpoint using curl instead of wget\n",
        "!curl -L -o sam_vit_h_4b8939.pth https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "\n",
        "SAM_CHECKPOINT = \"sam_vit_h_4b8939.pth\"\n",
        "MODEL_TYPE = \"vit_h\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM8BDuX7L_Pj"
      },
      "source": [
        "# Load the Model\n",
        "\n",
        "This cell loads the model into memory and prepares the `SamPredictor` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yO2s4EyL_Pk",
        "outputId": "e8e416cd-ec90-482c-aa66-5814703c79f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "\n",
            "✅ SAM Model and Predictor loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "from segment_anything import SamPredictor, sam_model_registry\n",
        "import torch\n",
        "# Check for GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the model\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=SAM_CHECKPOINT)\n",
        "sam.to(device=device)\n",
        "\n",
        "# Create the predictor object\n",
        "predictor = SamPredictor(sam)\n",
        "\n",
        "print(\"\\n✅ SAM Model and Predictor loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSiPOOYlL_Pm"
      },
      "source": [
        "# Data Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1Vk1si2TL_Pm"
      },
      "outputs": [],
      "source": [
        "# --- Create Directory Structure ---\n",
        "IMAGE_DIR = '/Users/cortesb/vip-amp-perception/AKS_cones/images'\n",
        "LABEL_DIR = '/Users/cortesb/vip-amp-perception/AKS_cones/masks'\n",
        "MASK_DIR = '/Users/cortesb/vip-amp-perception/AKS_cones/cropped_images'\n",
        "\n",
        "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
        "os.makedirs(LABEL_DIR, exist_ok=True)\n",
        "os.makedirs(MASK_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN54f1R5L_Pn"
      },
      "source": [
        "# Helper Functions\n",
        "\n",
        "Define two sets of helpers:\n",
        "1.  `parse_yolo_bbox`: To read `.txt` files and convert the normalized YOLO coordinates `[x_center, y_center, w, h]` into the absolute pixel coordinates `[x_min, y_min, x_max, y_max]` that SAM requires.\n",
        "2.  Plotting functions: (Taken from the official SAM examples) to help us visualize the results later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d9tNTOpL_Po",
        "outputId": "885d53af-cca2-44e5-b7f6-b93c99f7d862"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Helper functions defined.\n"
          ]
        }
      ],
      "source": [
        "def parse_yolo_bbox(label_path, image_shape):\n",
        "    \"\"\"Reads a YOLOv8 .txt file and converts boxes to [x_min, y_min, x_max, y_max] format.\"\"\"\n",
        "\n",
        "    if not os.path.exists(label_path):\n",
        "        return []\n",
        "\n",
        "    H, W = image_shape\n",
        "    boxes = []\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue\n",
        "\n",
        "            class_id = int(parts[0])\n",
        "            x_c_norm = float(parts[1])\n",
        "            y_c_norm = float(parts[2])\n",
        "            w_norm = float(parts[3])\n",
        "            h_norm = float(parts[4])\n",
        "\n",
        "            # Convert from normalized [x_c, y_c, w, h] to [x_min, y_min, x_max, y_max]\n",
        "            box_w = w_norm * W\n",
        "            box_h = h_norm * H\n",
        "            x_min = (x_c_norm * W) - (box_w / 2)\n",
        "            y_min = (y_c_norm * H) - (box_h / 2)\n",
        "            x_max = x_min + box_w\n",
        "            y_max = y_min + box_h\n",
        "\n",
        "            # Append as (class_id, [x1, y1, x2, y2])\n",
        "            boxes.append((class_id, [int(x_min), int(y_min), int(x_max), int(y_max)]))\n",
        "\n",
        "    return boxes\n",
        "\n",
        "# --- Visualization Helper Functions (from SAM examples) ---\n",
        "\n",
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - x0, box[3] - y0\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n",
        "\n",
        "print(\"✅ Helper functions defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_cmZjUJL_Pp"
      },
      "source": [
        "# Main Processing Loop\n",
        "\n",
        "This is the core of the notebook. It will:\n",
        "1.  Loop through every image in `IMAGE_DIR`.\n",
        "2.  Find its matching `.txt` file in `LABEL_DIR`.\n",
        "3.  Parse all bounding boxes from the `.txt` file.\n",
        "4.  **Filter for target class** (set `TARGET_CLASS_ID = 1` based on example `*.txt` file, which corresponds to cones).\n",
        "5.  Tell the `SamPredictor` to process the image.\n",
        "6.  For each target bounding box, ask the `Predictor` for a mask.\n",
        "7.  Save that mask as a simple black-and-white PNG file in `MASK_DIR`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3R3GuM4L_Pp",
        "outputId": "260e12e1-75ca-4ff3-e986-9d866c9b6b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting mask generation... Target Class ID: 1\n",
            "Looking for images in: /content/drive/MyDrive/AMP/Synthetic_Data/AKS_cones/images\n",
            "Saving masks to: /content/drive/MyDrive/AMP/Synthetic_Data/AKS_cones/masks\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6948/6948 [2:18:03<00:00,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ All images processed. Masks are saved in /content/dataset/masks/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import cv2\n",
        "TARGET_CLASS_ID = 1\n",
        "\n",
        "print(f\"Starting mask generation... Target Class ID: {TARGET_CLASS_ID}\")\n",
        "print(f\"Looking for images in: {IMAGE_DIR}\")\n",
        "print(f\"Saving masks to: {MASK_DIR}\")\n",
        "\n",
        "image_files = [f for f in os.listdir(IMAGE_DIR) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "if not image_files:\n",
        "    print(\"\\n--- WARNING: No images found in directory! ---\")\n",
        "\n",
        "for image_name in tqdm(image_files):\n",
        "    image_path = os.path.join(IMAGE_DIR, image_name)\n",
        "\n",
        "    # Construct the corresponding label path\n",
        "    base_name = os.path.splitext(image_name)[0]\n",
        "    label_name = base_name + \".txt\"\n",
        "    label_path = os.path.join(LABEL_DIR, label_name)\n",
        "\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image_shape = image.shape[:2] # (H, W)\n",
        "\n",
        "    # Get all bounding boxes for this image\n",
        "    boxes_info = parse_yolo_bbox(label_path, image_shape)\n",
        "\n",
        "    if not boxes_info:\n",
        "        # print(f\"No labels found for {image_name}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # --- Use SAM Predictor ---\n",
        "    # 1. Set the image in the predictor. This is a one-time operation per image.\n",
        "    predictor.set_image(image_rgb)\n",
        "\n",
        "    # 2. Iterate through all boxes found in the label file\n",
        "    box_index = 0\n",
        "    for class_id, box in boxes_info:\n",
        "\n",
        "        # 3. Only process boxes that match our target class (e.g., 'cone')\n",
        "        if class_id == TARGET_CLASS_ID:\n",
        "\n",
        "            # Define the potential output file path *first*\n",
        "            mask_filename = f\"{base_name}_mask_class{class_id}_{box_index}.png\"\n",
        "            mask_save_path = os.path.join(MASK_DIR, mask_filename)\n",
        "\n",
        "            # Check if this file already exists\n",
        "            if os.path.exists(mask_save_path):\n",
        "                # print(f\"Skipping existing mask: {mask_filename}\")\n",
        "                box_index += 1  # Increment the target box counter\n",
        "                continue      # Skip to the next box\n",
        "\n",
        "            # Convert box to numpy array for SAM\n",
        "            input_box = np.array(box)\n",
        "\n",
        "            # 4. Run prediction!\n",
        "            masks, scores, logits = predictor.predict(\n",
        "                box=input_box[None, :], # [None, :] adds a batch dimension\n",
        "                multimask_output=False  # Get only the single best mask\n",
        "            )\n",
        "\n",
        "            # masks is (1, H, W). Get the first and only mask.\n",
        "            mask = masks[0]\n",
        "\n",
        "            # Convert boolean mask to 8-bit grayscale image (0=black, 255=white)\n",
        "            mask_image_8bit = (mask * 255).astype(np.uint8)\n",
        "\n",
        "            # 5. Save the mask (path was already defined above)\n",
        "            cv2.imwrite(mask_save_path, mask_image_8bit)\n",
        "\n",
        "            box_index += 1 # Increment the target box counter after processing\n",
        "\n",
        "    # Reset the predictor for the next image\n",
        "    predictor.reset_image()\n",
        "\n",
        "print(\"\\n✅ All images processed. Masks are saved in /content/dataset/masks/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1pUL4a-L_Pq"
      },
      "source": [
        "## 7. Visualize a Result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od0Af332L_Pq"
      },
      "outputs": [],
      "source": [
        "import matplotlib as plt\n",
        "# --- Use the same example image from before ---\n",
        "\n",
        "example_img_path = os.path.join(IMAGE_DIR, \"0_Cross-Street-road-closure_jpg.rf.b268533f2d69236b4bda24587fe8eba8.jpg\")\n",
        "example_label_path = os.path.join(LABEL_DIR, \"0_Cross-Street-road-closure_jpg.rf.b268533f2d69236b4bda24587fe8eba8.txt\")\n",
        "\n",
        "if not os.path.exists(example_img_path):\n",
        "    print(f\"Cannot run visualization: Example image not found at {example_img_path}\")\n",
        "else:\n",
        "    # Load the image\n",
        "    image = cv2.imread(example_img_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    H, W = image_rgb.shape[:2]\n",
        "\n",
        "    # Load the boxes\n",
        "    boxes_info = parse_yolo_bbox(example_label_path, (H, W))\n",
        "    target_boxes = [box for class_id, box in boxes_info if class_id == TARGET_CLASS_ID]\n",
        "\n",
        "    # Load the generated masks\n",
        "    base_name = os.path.splitext(example_image_name)[0]\n",
        "    generated_masks = []\n",
        "    for i in range(len(target_boxes)):\n",
        "        mask_path = os.path.join(MASK_DIR, f\"{base_name}_mask_class{TARGET_CLASS_ID}_{i}.png\")\n",
        "        if os.path.exists(mask_path):\n",
        "            mask_8bit = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "            mask_bool = mask_8bit.astype(bool)\n",
        "            generated_masks.append(mask_bool)\n",
        "        else:\n",
        "            print(f\"Warning: Could not find expected mask {mask_path}\")\n",
        "\n",
        "    # --- Plotting ---\n",
        "    if not generated_masks:\n",
        "        print(\"No masks were generated for the example image. Cannot visualize.\")\n",
        "    else:\n",
        "        print(f\"Visualizing results for {example_image_name}...\")\n",
        "        plt.figure(figsize=(20, 10))\n",
        "\n",
        "        # Plot 1: Image + Bounding Boxes\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(image_rgb)\n",
        "        for box in target_boxes:\n",
        "            show_box(box, plt.gca())\n",
        "        plt.title(f\"Input Image + YOLO BBoxes (Class {TARGET_CLASS_ID})\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Plot 2: Image + Generated Masks\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(image_rgb)\n",
        "        for mask in generated_masks:\n",
        "            show_mask(mask, plt.gca(), random_color=True)\n",
        "        for box in target_boxes:\n",
        "            show_box(box, plt.gca())\n",
        "        plt.title(\"Output: Image + Generated SAM Masks\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Optional: Plot just the masks\n",
        "        plt.figure(figsize=(15, 7))\n",
        "        for i, mask in enumerate(generated_masks):\n",
        "            plt.subplot(1, len(generated_masks), i+1)\n",
        "            plt.imshow(mask, cmap='gray')\n",
        "            plt.title(f\"Mask {i}\")\n",
        "            plt.axis('off')\n",
        "        plt.suptitle(\"Raw Generated Masks (Saved as PNGs)\")\n",
        "        plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "vip",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
